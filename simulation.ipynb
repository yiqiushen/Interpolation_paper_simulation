{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a095987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tqdm, threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 numpy-2.3.2 scikit-learn-1.7.1 scipy-1.16.0 threadpoolctl-3.6.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c1012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mis-classification rate over 10 trials\n",
      "\n",
      " p\tLDA\tOLS-min-norm\tBayes\n",
      "100\t0.261\t0.439\t0.001\n",
      "200\t0.091\t0.102\t0.001\n",
      "400\t0.147\t0.195\t0.001\n",
      "800\t0.296\t0.300\t0.001\n",
      "1600\t0.387\t0.354\t0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# 1. Imports and helper utilities\n",
    "# ----------------------------------------------\n",
    "import numpy as np\n",
    "from numpy.linalg import pinv, norm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm.auto import trange\n",
    "\n",
    "def generate_data(n, p, theta, Sigma, rng):\n",
    "    \"\"\"\n",
    "    Draw n labelled observations from the two-component anisotropic\n",
    "    Gaussian mixture described in the paper.\n",
    "    \"\"\"\n",
    "    labels = rng.choice([-1, 1], size=n)\n",
    "    W = rng.multivariate_normal(np.zeros(p), Sigma, size=n)\n",
    "    Y = labels[:, None] * theta + W\n",
    "    return Y, labels\n",
    "\n",
    "def bayes_predict(x, theta, Sigma_inv):\n",
    "    \"\"\"Bayes oracle for balanced classes (threshold at 0).\"\"\"\n",
    "    return np.sign(x @ (Sigma_inv @ theta))\n",
    "\n",
    "def lda_fit_predict(Y_train, y_train, Y_test):\n",
    "    \"\"\"\n",
    "    Classical LDA using a pseudo-inverse when p > n.\n",
    "    scikit-learn handles the pseudo-inverse internally.\n",
    "    \"\"\"\n",
    "    clf = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "    clf.fit(Y_train, y_train)\n",
    "    return clf.predict(Y_test)\n",
    "\n",
    "def ols_min_norm(Y_train, y_train):\n",
    "    \"\"\"\n",
    "    Interpolating minimum-norm solution:\n",
    "        theta_hat = Y (YᵀY)⁺ y     (Moore–Penrose pseudo-inverse)\n",
    "    \"\"\"\n",
    "    return Y_train.T @ pinv(Y_train @ Y_train.T) @ y_train\n",
    "\n",
    "def evaluate(pred, true):\n",
    "    return np.mean(pred != true)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2. Core simulation loop\n",
    "# ----------------------------------------------\n",
    "def run_one_trial(n, p, delta, Sigma, rng):\n",
    "    \"\"\"\n",
    "    One Monte-Carlo trial:\n",
    "      • Draw theta with norm delta in the lowest-variance directions\n",
    "      • Form training and test sets\n",
    "      • Compare error of LDA, OLS interpolator, and the Bayes oracle\n",
    "    \"\"\"\n",
    "    # Choose theta aligned with the last coordinate (lowest eigenvalue)\n",
    "    theta = np.zeros(p)\n",
    "    theta[-1] = delta\n",
    "\n",
    "    # Pre-compute Sigma inverse once\n",
    "    Sigma_inv = np.diag(1.0 / np.diag(Sigma))\n",
    "\n",
    "    # Draw data\n",
    "    Y_train, y_train = generate_data(n, p, theta, Sigma, rng)\n",
    "    Y_test,  y_test  = generate_data(5000, p, theta, Sigma, rng)  # large test set\n",
    "\n",
    "    # LDA\n",
    "    y_pred_lda = lda_fit_predict(Y_train, y_train, Y_test)\n",
    "    err_lda = evaluate(y_pred_lda, y_test)\n",
    "\n",
    "    # Interpolating OLS\n",
    "    theta_ols = ols_min_norm(Y_train, y_train)\n",
    "    err_ols = evaluate(np.sign(Y_test @ theta_ols), y_test)\n",
    "\n",
    "    # Bayes oracle (needs true parameters)\n",
    "    y_pred_bayes = bayes_predict(Y_test, theta, Sigma_inv)\n",
    "    err_bayes = evaluate(y_pred_bayes, y_test)\n",
    "\n",
    "    return err_lda, err_ols, err_bayes\n",
    "\n",
    "def simulate(\n",
    "    n=100,\n",
    "    p_list=(100, 200, 400, 800, 1600),\n",
    "    delta=3.0,\n",
    "    sigma_large=3.0,\n",
    "    sigma_small=1.0,\n",
    "    trials=10,\n",
    "    seed=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Repeat the experiment over multiple ambient dimensions.\n",
    "    Sigma is diagonal with a pronounced anisotropy: first half\n",
    "    coordinates have large variance, remainder have small variance.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    results = {}\n",
    "\n",
    "    for p in p_list:\n",
    "        # Build anisotropic diagonal covariance\n",
    "        diag = np.concatenate([np.full(p // 2, sigma_large ** 2),\n",
    "                               np.full(p - p // 2, sigma_small ** 2)])\n",
    "        Sigma = np.diag(diag)\n",
    "\n",
    "        errs_lda, errs_ols, errs_bayes = [], [], []\n",
    "        for _ in trange(trials, leave=False):\n",
    "            e1, e2, e3 = run_one_trial(n, p, delta, Sigma, rng)\n",
    "            errs_lda.append(e1)\n",
    "            errs_ols.append(e2)\n",
    "            errs_bayes.append(e3)\n",
    "\n",
    "        results[p] = {\n",
    "            \"lda\":   np.mean(errs_lda),\n",
    "            \"ols\":   np.mean(errs_ols),\n",
    "            \"bayes\": np.mean(errs_bayes)\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 3. Example call (prints a table)\n",
    "# ----------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    res = simulate()\n",
    "    print(\"Average mis-classification rate over 10 trials\\n\")\n",
    "    print(\" p\\tLDA\\tOLS-min-norm\\tBayes\")\n",
    "    for p, val in res.items():\n",
    "        print(f\"{p}\\t{val['lda']:.3f}\\t{val['ols']:.3f}\\t{val['bayes']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
